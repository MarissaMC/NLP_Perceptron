CSCI 544 Homework 2
=====================
This is an instruction for CSCI544 Homework 2(http://appliednlp.bitbucket.org/hw2/index.html)

The code written for Python 3.4.


Part I
-----------------
The Averaged Perceptron classifier can be used as below:

    python3 perceplearn.py TRAININGFILE MODEL
	python3 percepclassify.py MODEL < TESTINGFILE > OUTPUT

Both TRAININGFILE and TESTINGFILE should have the same format as in homework1.


Part II
-----------------
Use my averaged perceptron to perform part-of-speech tagging.

The training program, postrain, run as follows:

    python3 postrain.py TRAININGFILE MODEL

where TRAININGFILE is the input file formated with one sentence per line, and each sentence composed of word/tag pairs. For example, a small training file might contain these lines:

This/DT is/VBZ a/DT test/NN ./.

I/PRP saw/VBD a/DT movie/NN ./.

I/PRP like/VBP cookies/NNS ./.


and MODEL is the output file containing the model.

The postag program runs as follows:

    python3 postag.py MODEL

where MODEL is the model generated by postrain.

postag takes its input from STDIN in the form of one sentence per line,
where each sentence is a sequence of words (without tags). Output will be written to STDOUT, 
and will be a tagged sentence (in the same format as the training data) for each input sentence.

Part III
-----------------
Use my averaged perceptron to perform named entity recogntion.

The method to use it is similar to Part II:

    python3 nelearn.py TRAININGFILE MODEL
	python3 netag.py MODEL < TESTINGFILE > OUTPUT
    
The NER data format is similar to the POS tagging data format, 
but also includes a POS tag between each word and its NER BIO tag: 

WORD/POSTAG/NERTAG WORD/POSTAG/NERTAG ...

Part IV
-----------------

### Accuracy of my part-of-speech tagger
After 5 iteration of Averaged Perceptron, my POS tagger accuracy is 93.4%

### Precision, recall and F-score for each named entity types and the overall F-score

B-LOC

Precision: 0.6052871467639015

Recall: 0.6747967479674797

F-score: 0.6381547333012973

B-PER

Precision: 0.4516276937184778

Recall: 0.8060556464811784

F-score: 0.578900969732589

B-MISC

Precision: 0.6507352941176471

Recall: 0.39775280898876403

F-score: 0.4937238493723849

B-ORG

Precision: 0.7228831350594822

Recall: 0.6076470588235294

F-score: 0.6602748481943113

I-LOC

Precision: 0.5899581589958159

Recall: 0.41839762611275966

F-score: 0.4895833333333333

I-PER

Precision: 0.84593837535014

Recall: 0.35157159487776485

F-score: 0.49671052631578955

I-MISC

Precision: 0.5833333333333334

Recall: 0.25688073394495414

F-score: 0.356687898089172

I-ORG

Precision: 0.6071428571428571

Recall: 0.46046852122986826

F-score: 0.5237302248126561

O

Precision: 0.9771206327133669

Recall: 0.9915115971426052

F-score: 0.9842635149923398

The overall F-score: 0.93

### Use my Naive Bayes classifier instead of my perceptron classifier